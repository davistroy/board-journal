# My honest field notes on being my own unreliable narrator + the governance mechanism I finally built to help

**Author:** Nate  
**Published:** January 5, 2026  
**Source:** [Nate's Newsletter](https://natesnewsletter.substack.com/p/the-rarest-thing-in-work-why-360)

---

## Introduction

For the last four centuries, personalized, honest perspective has been a luxury—but with AI, this kind of perspective is about to get a whole lot more accessible.

For most of history, one of the scarcest resources in professional life has been honest, multi-angle perspective on your own decisions. Not advice—advice is cheap and always has been. Perspective: the kind that comes from people who understand your situation, who will push back when you're rationalizing, who don't have any investment in protecting your feelings. The kind that holds you accountable across time to what you said you'd do versus what you actually did.

Kings had councils. CEOs have boards. For everyone else, there's been almost nothing. The occasional mentor, if you're lucky. A good manager, if you're luckier. A trusted friend who happens to understand your industry—but even they have to work with you tomorrow, which limits how hard they'll push.

The modern workplace has tried to solve this problem. The most common attempt is the 360-degree review—a process where you're evaluated by your manager, your peers, and your direct reports simultaneously, meant to surface a complete picture of how you're actually showing up at work. In theory, it democratizes feedback. In practice, it fails in specific, predictable ways.

I've been through dozens of them, on both sides. They happen once a year at most, often less. They're tied to promotions, which means everyone involved has incentives to game them. The people filling them out have twelve other reviews to complete and write two sentences each. And the rational move, if you're being reviewed, is to select your evaluators carefully and coach them on what to say. The feedback you get back is often contradictory—one person says you're too aggressive, another says you're not assertive enough—without enough context to know which signal matters. It's not that 360s are useless. It's that they were designed to solve an administrative problem, not to provide the kind of perspective that actually changes how you see yourself.

This piece is about something different: using AI to create the governance mechanism that's been missing. Not as a productivity hack or a gimmick—as an attempt to buy cheaply what has always been expensive. The same logic that puts boards and audits around companies, applied to your career.

I want to be clear about the limits upfront. AI doesn't make you a CEO. It doesn't replace a great coach or a mentor who's known you for years. But it does make a certain kind of scrutiny available that used to require either wealth or luck: structured pushback from multiple angles, infinite patience, no social cost for disagreement, and the ability to hold you to your own words across quarters. Not wise, but consistent. Not human, but also not charmed by your explanations.

The catch—and this is the whole point—is that it only works if you have the courage to design it for interrogation rather than reassurance. Left unconstrained, AI tends toward agreement. It mirrors the framing you give it. It becomes expensive journaling with better vocabulary. The mechanism isn't "talk to an AI about your career." The mechanism is "create a board that will actually push back, and submit yourself to its scrutiny."

## Here's what I'll cover:

- Why perspective has been structurally scarce and why 360 reviews don't solve it
- What's changed about the pressure people are under right now
- What I've actually built
- How to try a version of it yourself

---

## Grab the prompts

These prompts are designed around the failure modes this article describes: narrative drift, comfort-skill investment, avoided decisions that keep recurring.

The kit includes a quick version—fifteen minutes, five questions, to see if anything surfaces—and the full quarterly system with setup, board roles, and the main session.

### What makes them different from generic reflection prompts:

**They force receipts.** When you claim you did something, the prompt demands evidence—not "I worked on X" but "here's the artifact, here's the decision, here's where it lives." Calendar time doesn't count unless it's tied to an outcome. This is what prevents the gap between the story and what actually happened.

**They quote your words back to you.** When classifying whether a skill is appreciating or depreciating, the prompt asks three diagnostic questions, records your answers, then shows you exactly what you said before classifying. It's harder to fool yourself when you're looking at your own words.

**They gate on specificity.** Vague answers get stopped. "I could have been more proactive" isn't an avoided decision—a specific conversation you didn't have is. "Email and meetings" isn't comfort work—something you chose because it let you avoid risk is. The prompts don't proceed until you name the real thing.

**They end with falsifiable bets.** Every session produces a prediction you can check in ninety days, plus what evidence would prove it wrong. This is what creates accountability across quarters. You can't reinterpret "make progress" into success after the fact. Either the thing happened or it didn't.

If the quick version surfaces something you've been avoiding, the system is probably useful for you. If it doesn't, maybe you don't need it.

---

## Why this has always been rare

Good perspective is labor-intensive in ways that don't scale. It requires someone to learn your situation deeply—not just the facts but the politics, the personalities, the history of decisions that led to where you are now. It requires them to hold context across time, remembering what you said three months ago so they can ask whether you actually did it. And it requires them to be willing to create friction when it's easier to be encouraging, to tell you the thing you don't want to hear rather than the thing that makes the conversation comfortable.

All of this is emotionally costly for both sides. The person giving feedback risks the relationship every time they push hard. The person receiving it has to sit with discomfort rather than deflecting into defensiveness or rationalization. Most people, most of the time, avoid this cost. They give softer feedback than they mean. They accept vaguer answers than they should. The relationship survives, but the perspective never arrives.

Executive coaching exists because some people can pay to import this friction. Good coaches charge hundreds of dollars per hour, and they're often booked months out, precisely because the service is rare and the inputs don't compress. You can't automate learning someone's situation. You can't scale the willingness to create discomfort. Boards exist for companies because the stakes justify the expense—but the bar for having a personal board has always been "build something worth governing" or "know the right people." Mentorship programs try to democratize access, but a mentor who meets with you quarterly and has forty other mentees is not the same as a board that holds you accountable to specific commitments with specific evidence.

The result is that most people navigate their careers with only their own narrator—and the narrator is unreliable in predictable ways. I know this because I've watched myself do it for years.

## Being your own narrator

Here's what I've learned about self-assessment: I'm bad at it in predictable ways.

I tell myself I'm "being patient" about things when I'm actually avoiding the hard conversation. Patience sounds like maturity. It feels virtuous. But when I look honestly at situations where I've claimed patience, a lot of them were passivity dressed up in better language. I hadn't asked for the thing. I hadn't made the case. I'd just waited and called it strategy.

I tell myself my experience is valuable and hard to replace while ignoring signs that things are changing around me. Paying attention to those signs would mean confronting the possibility that skills I've invested years in might be worth less than they were. So I don't look too closely. I construct a story where I'm irreplaceable, and the story holds together well enough that I believe it.

I use activity as a proxy for progress. If I'm busy, I must be making headway. If my calendar is full and my task list is long, something important must be happening. But busy isn't the same as effective, and the feeling of motion isn't the same as actual movement toward something that matters. I've had entire quarters where I worked hard every day and couldn't point to a single thing that was different because of it. The busyness was comforting precisely because it obscured the fact that I was treading water.

These aren't character flaws. They're normal human cognition protecting itself from discomfort. The problem is that knowing this doesn't make me immune. The rationalizations happen faster than I can catch them. And without some external structure forcing scrutiny, they accumulate into drift—years of motion that don't add up to progress.

When I look honestly at my career, the periods where I drifted most were the periods with the least external accountability—no manager checking whether what I said matched what I did, no peer asking the questions I was avoiding, nobody forcing me to distinguish between the story and the receipts.

## What's changed

The cost of narrative drift has always been high. But right now, a lot of people are navigating career-defining pressure with no clear signal on whether they're doing it right.

Developers are watching peers claim they shipped ten billion tokens in 2025. Their managers are saying "catch up" without any framework for what catching up actually looks like. Is the peer exaggerating? Is the manager's expectation reasonable? Is the developer actually behind, or just telling themselves a story that they are? They have no way to know. The feedback loops that used to exist—code reviews, velocity metrics, peer comparison—don't map cleanly onto this new landscape. What they need isn't more advice on which tools to adopt. What they need is a board: a structure that forces them to articulate what they're actually doing, what evidence supports their assessment, and whether they're investing in skills that are appreciating or depreciating.

Product managers are being told to vibe code—to prototype and ship without waiting for engineering resources. But how do they know if they're doing it enough? How do they know if they're doing it right? Especially if the organization might need fewer of them next year? The usual signals—stakeholder feedback, roadmap ownership, launch metrics—don't answer the question that actually matters: is my role becoming more valuable or less? A manager won't tell them. A 360 review won't surface it. They need a board.

Finance professionals are trying to adopt AI without compromising the accuracy that their entire function depends on. Tools like automated expense categorization help, but the deeper question is career positioning: a six-hundred-year-old practice just changed, and nobody handed them a map. Their manager is figuring it out too. Their peers are just as lost. The professional development infrastructure that existed for decades—certifications, mentorship tracks, predictable promotions—doesn't account for the ground shifting this fast.

The common thread: everyone is being told to adapt, nobody knows if they're doing it right, and the usual sources of perspective—managers, peers, annual reviews—are failing them. This is exactly when you need a board. Not to tell you what to do, but to force clarity when everything around you is disorienting.

## Advice versus directed learning

There's a version of "AI democratizes learning" that's mostly meaningless. AI can teach you facts all day. It can summarize books, explain concepts, answer questions. That's useful, but it's not the edge. The edge is using AI to force judgment practice—to create situations where you have to make a call, defend it, and discover where your thinking breaks.

The difference between AI as advice (cheap and mostly useless) and AI as directed learning (cheap and compounding) is entirely in how you aim it. Advice is "tell me what to do." Directed learning is "pressure-test my reasoning until I find the weak point." The first makes you feel informed. The second makes you actually better at judgment—but only if the AI is constrained to push rather than agree.

Here's a concrete example. Say I'm preparing for a hard conversation—one where I need to ask for something and I expect resistance. The useless version is "AI, what should I say?" The useful version is: "Here's my argument. Role-play the pushback. Find the weakest point in my case. Force me to articulate the one sentence I'm avoiding." The first gives me a script I'll forget under pressure. The second forces me to practice the judgment call I'll actually face.

"Properly directed" means constraints: evidence required, tradeoffs named, disagreement built in, predictions that can be checked. Without those constraints, AI tends to mirror the framing you give it. With them, it becomes something closer to a sparring partner than a search engine.

## The mechanism

The system has two parts. The core insight is that AI doesn't need memory to be useful for this—it needs to ask hard questions about records you maintain yourself.

**Part one: a quarterly self-report.** Every three months, I run a prompt that interviews me about what actually happened. Not the version I'd put on LinkedIn—the real version. It asks: What did you say you were going to do? What did you actually do? Where's the gap? What decisions did you influence? What decisions did you avoid? What are you telling yourself is fine that might not be?

The interview is designed to be uncomfortable. When I say I "made progress," it asks what specifically changed. When I say something is "going well," it asks what evidence supports that. The output is a document—my board report—that's meant to invite scrutiny, not applause.

**Part two: the board meeting itself.** I've set up different voices I want in the room—a strategist who asks about long-term positioning, an accountability hawk who presses on what I said I'd do versus what I actually did, a skeptic whose job is to poke holes in whatever story I'm telling myself. I share my quarterly report, and the board pushes from multiple angles.

At the end of each session, I leave with: an honest assessment of where I am, specific concerns that emerged, concrete actions for the next ninety days, and one question I should be able to answer by next quarter that I can't answer now.

## What's in the board report

The mechanism is clearer if I show you what's actually in the document. Here are the fields:

**What I said I'd do.** Last quarter's commitments, copied verbatim. Not interpreted, not softened—exactly what I wrote down ninety days ago. Example: "Have the compensation conversation by end of February."

**What I actually did.** Not a story—receipts. Calendar entries, artifacts shipped, emails sent, decisions that got made. Example: "Had the conversation on February 23. Outcome: agreed to revisit in Q3 after the project ships." The discipline is specificity. "I worked on the strategy" doesn't count. A document that exists, a meeting where something changed, a shipped artifact—those count.

**Avoided decision.** Named specifically. Not "I could have been more proactive"—that's a feeling, not a decision. A specific conversation I didn't have, a risk I didn't take, a conflict I sidestepped. Example: "Didn't push back on the timeline even though I knew it was unrealistic. Chose to let it play out rather than be the one who raised the problem."

**Comfort work.** What I spent time on that felt productive but wasn't moving the needle. Work I'm good at that let me avoid work where I might fail. Example: "Spent six-plus hours on deck formatting that nobody noticed or cared about."

**Problem portfolio snapshot.** The three to five problems I'm actually solving for, with rough time allocation. Not my job title, not my skills—what would go unsolved if I disappeared. Example: "Cross-team coordination (40%), analysis quality (30%), translating for decision-makers (20%), process documentation (10%)."

**Next-quarter bet.** One falsifiable prediction. Not "I'll make progress on X"—something specific enough that next quarter I can say "yes, this happened" or "no, it didn't." Example: "By end of Q2, I will have led the prioritization conversation for the roadmap, not just contributed to it."

Quarter one is useful. It's good to see the gaps between intention and action. But quarter four is the point. The record makes patterns undeniable. You can see which avoided decisions keep recurring, which suggests deep avoidance rather than bad timing. You can see whether your problem portfolio is actually shifting or whether you're stuck. You can see which bets you got right versus wrong, which tells you something about your own calibration.

## Questions I ask myself about my work

One thing that's been useful is getting specific about the problems I'm actually paid to solve—not my job title or my skills, but the three to five things that would go unsolved if I disappeared. I call this my "problem portfolio." For each problem, I ask myself:

**How many other people could solve this without supervision?** If the answer is "lots," it's probably not that valuable. The problems worth protecting are the ones where the list of people who can do them well is short.

**What breaks if it's solved poorly—money, trust, speed, safety?** High-consequence problems are worth more. If the downside of getting it wrong is severe, the skill to get it right is more valuable.

**Does AI make this cheaper to do, or does it make mistakes more expensive to miss?** Some problems are getting automated. Others are getting more judgment-intensive because the volume of output makes quality control harder. The first type is depreciating. The second type is appreciating.

**Does this skill travel?** Judgment that transfers across contexts is worth more than knowledge that only works in one place. If I can only apply this skill in my current company with my current team, it's less valuable than a skill I could take anywhere.

These questions have helped me see which problems I should be protecting and getting better at, which ones I should be delegating or automating, and which ones I should be moving toward even though they're less comfortable. The uncomfortable discovery: I'd been spending a lot of time on problems that were getting cheaper while avoiding the ones that were getting more valuable.

## Rules I set for myself

The obvious failure mode is that I could tell the AI whatever I want to hear. It would be easy to write a self-report that makes me look good, get the board to agree that I'm doing great, and walk away feeling validated without having learned anything. So I've built in rules to make that harder:

**Receipts only.** Every claim I make in my report has to point to something observable—a calendar entry, an artifact I shipped, a decision that got made, a metric that moved. If I can't point to evidence, I have to label it as "narrative" rather than fact. This forces me to distinguish between what actually happened and the story I'm telling about what happened.

**Name one decision I avoided.** This is the most useful rule. Every quarter, I have to identify something I could have pushed on but didn't—a conversation I avoided, a risk I didn't take, a conflict I sidestepped. Naming it doesn't mean I have to fix it, but it does mean I can't pretend it doesn't exist.

**One falsifiable bet.** The board has to produce one prediction I can check against reality in ninety days. Not "I'll make progress on X" but something specific enough that next quarter I can say "yes, this happened" or "no, it didn't." This creates accountability that persists across sessions. You can't reinterpret vague language into success after the fact.

**Name one comfort-work item.** I have to identify one thing I'm doing because it feels productive, not because it's actually moving the needle. Work I'm good at that lets me avoid work I'm bad at. Staying busy with the familiar instead of wrestling with the unfamiliar. Naming it is the first step to stopping it.

## What this looks like in practice

The board meetings tend to follow a pattern. I come in with a goal I thought I was pursuing—"be more strategic," say. The board asks what decision changed because of my work. I point to an analysis I'm proud of. The board asks who acted differently because of it. The answer is usually nobody. Then it asks what assumption I avoided challenging because I didn't want the friction. That's when the real conversation starts.

The process takes a vague aspiration, finds the gap between intention and action, names the avoidance, and converts it into something falsifiable: "Bring one contested assumption into a meeting. Name the uncertainty. Log what happens."

A different session caught a different trap. I'd spent a quarter improving my analysis quality—cleaner models, better documentation, faster turnaround. The board asked whether analysis quality was still the scarce skill on my team. A year ago, I was one of the few people who could do it well. Now more people can; the tools are better. So I'd spent three months getting better at something that was getting less scarce. The question I hadn't asked myself: what's the problem fewer people can solve? Probably getting leadership to act on the analysis—translating it into decisions, navigating the politics, making the case in a way that actually moved people. Time I'd spent on that: almost none.

I wouldn't have seen that on my own. The board didn't tell me what to do. It asked the question that made the mispricing visible.

## What it forced me to confront

The value isn't that AI reveals information you didn't have. It's that the structure forces confrontation with information you're already ignoring.

For years, I was told by smart people I respected that I should start creating content publicly—a blog, a video channel, something. Build a professional profile beyond my job. Practice telling stories about what I was learning. The advice was good. The people giving it understood my situation. They explained how it would help: it would improve my product storytelling inside the business, help with hiring, give me a professional identity that wasn't dependent on my current employer. One of them laid out the costs explicitly: you're limiting your career options, you're not building leverage, you're making yourself dependent on your job title in a way that will hurt you eventually.

And I ignored it for years. I told myself it was scary. I told myself I didn't have time. I told myself I'd get to it later. I eventually got there on my own—but it took far too long, and the delay cost me.

Here's what I learned from that experience: having one outside voice wasn't enough. Even having several wasn't enough. It was too easy to nod along, agree it was a good idea, and then change nothing. A single voice—even a smart, well-informed one—is easy to rationalize away. What I needed was the structure of a board: multiple angles, direct confrontation, specific costs articulated, a record that accumulated over time so the pattern of avoidance became undeniable.

I built this system because I didn't have it when I needed it. The storytelling avoidance is the kind of thing the board is designed to catch—and catch faster than I caught it on my own.

## The pattern that kept showing up

I'd been telling myself I was "waiting for the right moment" to have a compensation conversation. The board flagged it as an avoided decision two quarters in a row. Same language, same rationalization, same inaction.

The third quarter, the rule forced me to either name it again—which would make the pattern undeniable—or do something about it. I had the conversation within two weeks. It didn't go the way I'd hoped; the answer was "not now, but let's revisit after Q3." But that clarity was more useful than another six months of "waiting for the right moment." I knew where I stood. I could make decisions based on reality instead of the story I'd been telling myself.

That's the value: not motivation, not inspiration, but forcing action on things I was avoiding and getting real information back. The system doesn't make the conversation easier. It makes the avoidance harder to sustain.

## What accumulates

The first quarter is useful. The fourth quarter is the point.

Over time, patterns become undeniable. The storytelling avoidance I mentioned didn't surface in one session—it surfaced as a streak. Quarter after quarter, the same avoided decision, always with a new rationalization but the same inaction underneath. Once I could see the streak, I couldn't unsee it. That's not a coincidence; that's a pattern I was hiding from myself. The system didn't diagnose this. The record did.

The comfort-work pattern was worse. I kept naming different tasks as comfort work each quarter, but when I looked back at them together, they were all the same type: work I was good at that let me avoid work where I might fail. The board didn't catch this. The accumulation of my own answers did.

Calibration was humbling. I got about half my falsifiable bets wrong—not randomly, but systematically optimistic about timelines and systematically overconfident about my influence on decisions. That's information I wouldn't have gotten any other way. It's easy to revise your memory of what you predicted. It's harder when it's written down and you have to look at it.

The problem portfolio shift was the slowest and most valuable. Quarter by quarter, I could see whether I was actually moving toward scarcer problems or just claiming I would. By quarter four, the time allocation told the real story—and it wasn't the one I'd been telling myself.

## Why most people won't do this

Perspective just became cheap. For the first time in centuries, you can access something like a board—multiple angles, structured pushback, accountability across time—without being wealthy or lucky or running a company.

Most people won't use it.

Not because it's expensive—it's nearly free. Not because it's complicated—it isn't. Because they don't actually want perspective. They want validation. They want to be told that what they're doing makes sense, that their skills are still valuable, that the story they're telling themselves is true. The scarcity was never just access to outside viewpoints. It was willingness to submit to scrutiny.

I ran a session early on where I fed the board only flattering inputs—my best work, my cleanest wins. It told me I was doing great. I left feeling praised and learned nothing. That's when I added the "name one avoided decision" rule. That's when I realized the system only works if you design it to press you, and you only design it to press you if you actually want to see clearly more than you want to feel good.

The question isn't whether you can afford perspective. The question is whether you'll use it honestly.

## Trying it yourself

A low-friction way to test whether this approach is useful for you: run one prompt that asks you to identify the three to five problems you're actually paid to solve—not your job title, not your skills, but what would go unsolved if you disappeared. Then ask the four questions I mentioned about each one: How many others could solve this? What breaks if it's solved poorly? Is AI making this cheaper or mistakes more expensive? Does this skill transfer?

See if anything surfaces that you've been avoiding. If it does, you'll know whether this kind of structured scrutiny is useful for you. If it doesn't—if you can answer those questions cleanly and nothing uncomfortable emerges—maybe you don't need it.

I don't know if this is the best system or just one that happens to work for me. What I do know is that I'm less likely to drift when I have to articulate what I'm doing, defend it to something that pushes back, and leave with receipts. The stakes are real: years, options, autonomy. This is governance over an asset that deserves it.

## The risks

**AI can help you rationalize.** If you approach this looking for validation, you'll find it. The system only works if you design it to press you. Symptoms that you're gaming it: you leave feeling praised, you can't point to one uncomfortable sentence you said out loud, or your bet isn't actually falsifiable.

**Privacy is real.** Policies differ by provider and plan; assume retention is possible unless you've verified your settings. My approach: I redact names and identifiable details. The system works with the structure of problems, not the specifics. For anything truly sensitive, I abstract into categories or use a local model.

**False certainty.** The board can sound confident when it's generating plausible-sounding observations. I treat its output as hypotheses to investigate, not conclusions to accept. The useful part isn't the AI's wisdom—it's the process of having to prepare, articulate, and defend.

**Personality mismatch.** This works for me because I respond well to adversarial reflection. If that feels destabilizing rather than clarifying, a human peer or coach may serve you better.

I don't know if this is the best system or just one that happens to work for me. What I do know is that I'm less likely to drift when I have to articulate what I'm doing, defend it to something that pushes back, and leave with receipts.

The stakes are real: years, options, autonomy. This is governance over an asset that deserves it.

---

*Downloaded from Nate's Newsletter - 1/10/2026*
